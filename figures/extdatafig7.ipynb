{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ext. Data Figure 7: Model Selection and Control Data Analyses for the GLM-HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook recreates the figure panels included in Extended Data Figure 7 of [Bolkan, Stone et al 2021](https://www.biorxiv.org/content/10.1101/2021.07.23.453573v1). \n",
    "\n",
    "The general premise of this notebook/figure, in the context of the paper, is to demonstrate how we selected certain model parameters and to show the results of some analyses conducted on the control group (a group of no-opsin mice for which the laser was on for a subset of trials, in the same manner as the experimental groups, but for which the laser should have no inhibiting effect on behavior). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the required code packages and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import pickle\n",
    "from glmhmm import glm, glm_hmm\n",
    "from glmhmm.utils import find_best_fit, crossval_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data for the indirect pathway cohort\n",
    "x_d2 = np.load('data/indirect_x.npy') # z-scored design matrix\n",
    "y_d2 = np.load('data/indirect_y.npy') # vector of right and left choices for each trial\n",
    "sessions_d2 = np.load('data/indirect_sessions.npy') # vector of session start and stop indices\n",
    "mouseIDs_d2 = np.load('data/indirect_mouseIDs.npy') # vector of mouse IDs for each trial\n",
    "\n",
    "# load the data for the direct pathway cohort\n",
    "x_d1 = np.load('data/direct_x.npy') # z-scored design matrix\n",
    "y_d1 = np.load('data/direct_y.npy') # vector of right and left choices for each trial\n",
    "sessions_d1 = np.load('data/direct_sessions.npy') # vector of session start and stop indices\n",
    "mouseIDs_d1 = np.load('data/direct_mouseIDs.npy') # vector of mouse IDs for each trial\n",
    "\n",
    "# load the data for the direct pathway cohort\n",
    "x_ct = np.load('data/control_x.npy') # z-scored design matrix\n",
    "y_ct = np.load('data/control_y.npy') # vector of right and left choices for each trial\n",
    "sessions_ct = np.load('data/control_sessions.npy') # vector of session start and stop indices\n",
    "mouseIDs_ct = np.load('data/control_mouseIDs.npy') # vector of mouse IDs for each trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ext. Data Figure 7A: Cross Validation across States\n",
    "#### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [55,38,13,23,103]\n",
    "xtrain_d2,xtest_d2,ytrain_d2,ytest_d2,sesstrain_d2,sesstest_d2,testIx_d2,_ = crossval_split(x_d2, y_d2,\n",
    "                                                                                            sessions_d2,\n",
    "                                                                                            mouseIDs_d2,\n",
    "                                                                                            test_size=0.2, \n",
    "                                                                                            seeds=seeds)\n",
    "        \n",
    "seeds = [10,66,100,73,200]\n",
    "xtrain_d1,xtest_d1,ytrain_d1,ytest_d1,sesstrain_d1,sesstest_d1,testIx_d1,_ = crossval_split(x_d1, y_d1,\n",
    "                                                                                            sessions_d1,\n",
    "                                                                                            mouseIDs_d1,\n",
    "                                                                                            test_size=0.2, \n",
    "                                                                                            seeds=seeds)\n",
    "\n",
    "seeds = [0,7,237,411,219]\n",
    "xtrain_ct,xtest_ct,ytrain_ct,ytest_ct,sesstrain_ct,sesstest_ct,testIx_ct,_ = crossval_split(x_ct, y_ct,\n",
    "                                                                                            sessions_ct,\n",
    "                                                                                            mouseIDs_ct,\n",
    "                                                                                            test_size=0.2, \n",
    "                                                                                            seeds=seeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the hyperparmeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 2 # number of observation classes\n",
    "D = x_d2.shape[1] # number of GLM inputs (regressors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the training sets\n",
    "This takes a foolish amount of time to run (like, almost a week -- average ~2 hours per fit x 5 sets of states x 5 training sets x 3 cohorts). The code is presented as it is here for clarity and instructional purposes but it is not actually advised to run this in a series of for loops. We strongly recommend taking this code out of the for loops and parallelizing/running as separate jobs on a remote server in order to cut down on the computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inits = 20 # set the number of initializations\n",
    "maxiter = 250 # maximum number of iterations of EM to allow for each fit\n",
    "tol = 1e-3\n",
    "folds = len(seeds)\n",
    "states = 5\n",
    "\n",
    "# store model objects for each simulated dataset\n",
    "best_GLMHMMs_d2 = np.zeros((states,folds), dtype=object)\n",
    "best_GLMHMMs_d1 = np.zeros((states,folds), dtype=object)\n",
    "best_GLMHMMs_ct = np.zeros((states,folds), dtype=object)\n",
    "\n",
    "for k in range(states):\n",
    "    K = k+1\n",
    "    for j in range(folds):\n",
    "        # store values for each initialization\n",
    "        lls_all_d2 = np.zeros((inits,maxiter))\n",
    "        GLMHMMs_d2 = np.zeros((inits),dtype=object)\n",
    "        lls_all_d1 = np.zeros((inits,maxiter))\n",
    "        GLMHMMs_d1 = np.zeros((inits),dtype=object)\n",
    "        lls_all_ct = np.zeros((inits,maxiter))\n",
    "        GLMHMMs_ct = np.zeros((inits),dtype=object)\n",
    "\n",
    "        # fit the models for each initialization\n",
    "        for i in range(inits):\n",
    "            \n",
    "            if K == 1:\n",
    "                ## indirect pathway cohort --------------------------------------------------------\n",
    "                GLM_d2 = glm.GLM(N_d2,M,C,observations=\"bernoulli\")\n",
    "                w_init_d1 = GLM_d2.init_weights()\n",
    "                w_d2, phi_d2 = GLM_d2.fit(xtrain_d2[j],w_init_d2,ytrain_d2[j])\n",
    "                \n",
    "                ## direct pathway cohort --------------------------------------------------------\n",
    "                GLM_d1 = glm.GLM(N_d1,M,C,observations=\"bernoulli\")\n",
    "                w_init_d1 = GLM_d1.init_weights()\n",
    "                w_d1, phi_d1 = GLM_d1.fit(xtrain_d1[j],w_init_d1,ytrain_d1[j])\n",
    "                \n",
    "                ## control cohort --------------------------------------------------------\n",
    "                GLM_ct = glm.GLM(N_d1,M,C,observations=\"bernoulli\")\n",
    "                w_init_d1 = GLM_ct.init_weights()\n",
    "                w_ct, phi_ct = GLM_ct.fit(xtrain_ct[j],w_init_ct,ytrain_ct[j])\n",
    "            \n",
    "            else:\n",
    "                ## indirect pathway cohort --------------------------------------------------------\n",
    "                GLMHMMs_d2[i] = glm_hmm.GLMHMM(N_d2,D,C,K,observations=\"bernoulli\",gaussianPrior=1)\n",
    "                A_init,w_init,_ = GLMHMMs_d2[i].generate_params(weights=['GLM',-0.2,1.2,xtrain_d2[j],ytrain_d2[j],1])\n",
    "                lls_all_d2[i,:],_,_,_ = GLMHMMs_d2[i].fit(ytrain_d2[j],xtrain_d2[j],A_init,w_init,\n",
    "                                                          maxiter=maxiter,tol=tol,sess=sesstrain_d2[j])\n",
    "\n",
    "                ## direct pathway cohort ----------------------------------------------------------\n",
    "                GLMHMMs_d1[i] = glm_hmm.GLMHMM(N_d1,D,C,K,observations=\"bernoulli\",gaussianPrior=1)\n",
    "                A_init,w_init,_ = GLMHMMs_d1[i].generate_params(weights=['GLM',-0.2,1.2,xtrain_d1[j],ytrain_d1[j],1])\n",
    "                lls_all_d1[i,:],_,_,_ = GLMHMMs_d1[i].fit(ytrain_d1[j],xtrain_d1[j],A_init,w_init,\n",
    "                                                          maxiter=maxiter,tol=tol,sess=sesstrain_d1[j])\n",
    "\n",
    "                ## control cohort ----------------------------------------------------------\n",
    "                GLMHMMs_ct[i] = glm_hmm.GLMHMM(N_d1,D,C,K,observations=\"bernoulli\",gaussianPrior=1)\n",
    "                A_init,w_init,_ = GLMHMMs_ct[i].generate_params(weights=['GLM',-0.2,1.2,xtrain_ct[j],ytrain_ct[j],1])\n",
    "                lls_all_ct[i,:],_,_,_ = GLMHMMs_ct[i].fit(ytrain_ct[j],xtrain_ct[j],A_init,w_init,\n",
    "                                                          maxiter=maxiter,tol=tol,sess=sesstrain_ct[j])\n",
    "\n",
    "        if K  == 1:\n",
    "            best_GLMHMMs_d2[k,j] = GLM_d2\n",
    "            best_GLMHMMs_d1[k,j] = GLM_d1\n",
    "            best_GLMHMMs_ct[k,j] = GLM_ct\n",
    "            \n",
    "        else:\n",
    "            # find the initialization that led to the best fit\n",
    "            bestix_d2 = find_best_fit(lls_all_d2)\n",
    "            best_GLMHMMs_d2[k,j] = GLMHMMs_d2[bestix_d2]\n",
    "            bestix_d1 = find_best_fit(lls_all_d1)\n",
    "            best_GLMHMMs_d1[k,j] = GLMHMMs_d1[bestix_d1]    \n",
    "            bestix_ct = find_best_fit(lls_all_ct)\n",
    "            best_GLMHMMs_ct[k,j] = GLMHMMs_ct[bestix_ct]  \n",
    "    \n",
    "# save results in case we want to use them again later\n",
    "pickle.dump(best_GLMHMMs_d2, open('fit models/training_states_GLMHMMs_d2.pickle', 'wb'))\n",
    "pickle.dump(best_GLMHMMs_d1, open('fit models/training_states_GLMHMMs_d1.pickle', 'wb'))\n",
    "pickle.dump(best_GLMHMMs_ct, open('fit models/training_states_GLMHMMs_ct.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ext. Data Figure 7a: Selecting the Number of States for the GLM-HMM\n",
    "From the plots below, we see that the cross-validated log-likelihood starts to plateau around 3-4 states. From this, we decided to use the 3-state GLM-HMM for all analyses in the paper. For more on the 4-state GLM-HMM, see <b>Extended Data Figure 7d/e</b> further down in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
